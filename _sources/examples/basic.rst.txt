–ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã
===============

–≠—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Evolution LangChain.

–ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
--------------

–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

.. code-block:: python

   from evolution_langchain import EvolutionInference

   # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
   llm = EvolutionInference(
       model="your-model-name",
       key_id="your-key-id",
       secret="your-secret",
       base_url="https://your-api-endpoint.com/v1"
   )

   # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
   response = llm.invoke("–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?")
   print(response)

–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
------------------

–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ:

.. code-block:: python

   from evolution_langchain import EvolutionInference

   llm = EvolutionInference(
       model="your-model-name",
       key_id="your-key-id",
       secret="your-secret",
       base_url="https://your-api-endpoint.com/v1"
   )

   # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–º–ø—Ç–æ–≤
   prompts = [
       "–ß—Ç–æ —Ç–∞–∫–æ–µ Python?",
       "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
       "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?"
   ]

   # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
   responses = llm.generate(prompts)

   # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
   for i, generation_list in enumerate(responses.generations):
       print(f"–í–æ–ø—Ä–æ—Å {i+1}: {prompts[i]}")
       print(f"–û—Ç–≤–µ—Ç: {generation_list[0].text}")
       print("-" * 50)

–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
--------------------

–ü—Ä–∏–º–µ—Ä —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:

.. code-block:: python

   from evolution_langchain import EvolutionInference

   # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
   llm = EvolutionInference(
       model="your-model-name",
       key_id="your-key-id",
       secret="your-secret",
       base_url="https://your-api-endpoint.com/v1",
       temperature=0.7,        # –ö–æ–Ω—Ç—Ä–æ–ª—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏
       max_tokens=500,         # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
       top_p=0.9,             # Nucleus sampling
       frequency_penalty=0.1,  # –®—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
       presence_penalty=0.1    # –®—Ç—Ä–∞—Ñ –∑–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ
   )

   # –ó–∞–ø—Ä–æ—Å —Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
   response = llm.invoke("–†–∞—Å—Å–∫–∞–∂–∏ –∫–æ—Ä–æ—Ç–∫—É—é –∏—Å—Ç–æ—Ä–∏—é –æ —Ä–æ–±–æ—Ç–µ")
   print(response)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
----------------------------------

–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:

.. code-block:: python

   import os
   from evolution_langchain import EvolutionInference

   # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
   llm = EvolutionInference(
       model=os.getenv("EVOLUTION_MODEL"),
       key_id=os.getenv("EVOLUTION_KEY_ID"),
       secret=os.getenv("EVOLUTION_SECRET"),
       base_url=os.getenv("EVOLUTION_BASE_URL")
   )

   response = llm.invoke("–ü—Ä–∏–≤–µ—Ç!")
   print(response)

–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
-------------------

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤:

.. code-block:: python

   import asyncio
   from evolution_langchain import EvolutionInference

   async def async_example():
       llm = EvolutionInference(
           model="your-model-name",
           key_id="your-key-id",
           secret="your-secret",
           base_url="https://your-api-endpoint.com/v1"
       )

       # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –æ–¥–∏–Ω–æ—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
       response = await llm.ainvoke("–†–∞—Å—Å–∫–∞–∂–∏ –æ –∫–≤–∞–Ω—Ç–æ–≤—ã—Ö –∫–æ–º–ø—å—é—Ç–µ—Ä–∞—Ö")
       print(response)

       # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –ø–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
       prompts = ["–í–æ–ø—Ä–æ—Å 1", "–í–æ–ø—Ä–æ—Å 2", "–í–æ–ø—Ä–æ—Å 3"]
       responses = await llm.agenerate(prompts)
       
       for i, generation_list in enumerate(responses.generations):
           print(f"–û—Ç–≤–µ—Ç {i+1}: {generation_list[0].text}")

   # –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
   asyncio.run(async_example())

–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
----------------

–ë–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫:

.. code-block:: python

   from evolution_langchain import EvolutionInference

   llm = EvolutionInference(
       model="your-model-name",
       key_id="your-key-id",
       secret="your-secret",
       base_url="https://your-api-endpoint.com/v1"
   )

   try:
       response = llm.invoke("–ü—Ä–∏–≤–µ—Ç!")
       print(response)
   except Exception as e:
       print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
       print(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")

–ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä
-------------

–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –±–∞–∑–æ–≤—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π:

.. code-block:: python

   import os
   from evolution_langchain import EvolutionInference

   def main():
       print("üöÄ Evolution LangChain - –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã")
       print("=" * 50)

       # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
       llm = EvolutionInference(
           model=os.getenv("EVOLUTION_MODEL", "your-model-name"),
           key_id=os.getenv("EVOLUTION_KEY_ID", "your-key-id"),
           secret=os.getenv("EVOLUTION_SECRET", "your-secret"),
           base_url=os.getenv("EVOLUTION_BASE_URL", "https://your-api-endpoint.com/v1"),
           temperature=0.7,
           max_tokens=200
       )

       print("‚úÖ –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
       print(f"üìù –ú–æ–¥–µ–ª—å: {llm.model}")
       print(f"üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {llm.temperature}")
       print(f"üéØ Max tokens: {llm.max_tokens}")
       print()

       # 1. –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
       print("1. –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å:")
       try:
           response = llm.invoke("–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ –∫—Ä–∞—Ç–∫–æ.")
           print(f"–û—Ç–≤–µ—Ç: {response}")
       except Exception as e:
           print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
       print()

       # 2. –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
       print("2. –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞:")
       questions = [
           "–ß—Ç–æ —Ç–∞–∫–æ–µ Python?",
           "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?"
       ]

       try:
           responses = llm.generate(questions)
           for i, response in enumerate(responses.generations):
               print(f"–í–æ–ø—Ä–æ—Å {i+1}: {questions[i]}")
               print(f"–û—Ç–≤–µ—Ç: {response[0].text}")
               print()
       except Exception as e:
           print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
       print()

       print("üéâ –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")

   if __name__ == "__main__":
       main()

–ß—Ç–æ –¥–∞–ª—å—à–µ?
-----------

- –ò–∑—É—á–∏—Ç–µ :doc:`chains` –¥–ª—è –ø—Ä–∏–º–µ—Ä–æ–≤ —Å LangChain —Ü–µ–ø–æ—á–∫–∞–º–∏
- –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ :doc:`advanced` –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
- –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ :doc:`../guide/basics` –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ 